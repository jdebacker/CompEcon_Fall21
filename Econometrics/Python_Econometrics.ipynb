{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econometric Methods in Python\n",
    "### by [Jason DeBacker](http://jasondebacker.com), October 2021\n",
    "\n",
    "This notebook illustrates some of the econometric tools available in Python by estimating OLS and IV models.\n",
    "\n",
    "To illustrate OLS and IV estimators, we'll use some example data from an econometic textbook.  We'll take an example dataset from the book by Christian Kleiber and Achim Zeileis (2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import linearmodels as lm\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 1976 PSID data from csv file\n",
    "PSID1976 = pd.read_csv('PSID1976.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # OLS and IV\n",
    "\n",
    "We'll look at the implementation of OLS and IV estimators by estimating models of female labor supply.  We'll do this with data on married women from the 1976 PSID.  This example comes from [this](https://www.r-bloggers.com/instrumental-variables-in-r-exercises-part-3/) exercise from R-bloggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>participation</th>\n",
       "      <th>hours</th>\n",
       "      <th>youngkids</th>\n",
       "      <th>oldkids</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>wage</th>\n",
       "      <th>repwage</th>\n",
       "      <th>hhours</th>\n",
       "      <th>...</th>\n",
       "      <th>hwage</th>\n",
       "      <th>fincome</th>\n",
       "      <th>tax</th>\n",
       "      <th>meducation</th>\n",
       "      <th>feducation</th>\n",
       "      <th>unemp</th>\n",
       "      <th>city</th>\n",
       "      <th>experience</th>\n",
       "      <th>college</th>\n",
       "      <th>hcollege</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>1610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>3.3540</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2708</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0288</td>\n",
       "      <td>16310</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>no</td>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1.3889</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2310</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4416</td>\n",
       "      <td>21800</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>4.5455</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3072</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5807</td>\n",
       "      <td>21040</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>no</td>\n",
       "      <td>15</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0965</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5417</td>\n",
       "      <td>7300</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>1568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4.5918</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>27300</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 participation  hours  youngkids  oldkids  age  education  \\\n",
       "0           1           yes   1610          1        0   32         12   \n",
       "1           2           yes   1656          0        2   30         12   \n",
       "2           3           yes   1980          1        3   35         12   \n",
       "3           4           yes    456          0        3   34         12   \n",
       "4           5           yes   1568          1        2   31         14   \n",
       "\n",
       "     wage  repwage  hhours  ...    hwage  fincome     tax  meducation  \\\n",
       "0  3.3540     2.65    2708  ...   4.0288    16310  0.7215          12   \n",
       "1  1.3889     2.65    2310  ...   8.4416    21800  0.6615           7   \n",
       "2  4.5455     4.04    3072  ...   3.5807    21040  0.6915          12   \n",
       "3  1.0965     3.25    1920  ...   3.5417     7300  0.7815           7   \n",
       "4  4.5918     3.60    2000  ...  10.0000    27300  0.6215          12   \n",
       "\n",
       "   feducation  unemp  city  experience college  hcollege  \n",
       "0           7    5.0    no          14      no        no  \n",
       "1           7   11.0   yes           5      no        no  \n",
       "2           7    5.0    no          15      no        no  \n",
       "3           7    5.0    no           6      no        no  \n",
       "4          14    9.5   yes           7     yes        no  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data from the 1976 PSID and look at first 5 rows\n",
    "PSID1976.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hours</th>\n",
       "      <th>youngkids</th>\n",
       "      <th>oldkids</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>wage</th>\n",
       "      <th>repwage</th>\n",
       "      <th>hhours</th>\n",
       "      <th>hage</th>\n",
       "      <th>heducation</th>\n",
       "      <th>hwage</th>\n",
       "      <th>fincome</th>\n",
       "      <th>tax</th>\n",
       "      <th>meducation</th>\n",
       "      <th>feducation</th>\n",
       "      <th>unemp</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>753.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>740.576361</td>\n",
       "      <td>0.237716</td>\n",
       "      <td>1.353254</td>\n",
       "      <td>42.537849</td>\n",
       "      <td>12.286853</td>\n",
       "      <td>2.374565</td>\n",
       "      <td>1.849734</td>\n",
       "      <td>2267.270916</td>\n",
       "      <td>45.120850</td>\n",
       "      <td>12.491368</td>\n",
       "      <td>7.482179</td>\n",
       "      <td>23080.594954</td>\n",
       "      <td>0.678863</td>\n",
       "      <td>9.250996</td>\n",
       "      <td>8.808765</td>\n",
       "      <td>8.623506</td>\n",
       "      <td>10.63081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.516666</td>\n",
       "      <td>871.314216</td>\n",
       "      <td>0.523959</td>\n",
       "      <td>1.319874</td>\n",
       "      <td>8.072574</td>\n",
       "      <td>2.280246</td>\n",
       "      <td>3.241829</td>\n",
       "      <td>2.419887</td>\n",
       "      <td>595.566649</td>\n",
       "      <td>8.058793</td>\n",
       "      <td>3.020804</td>\n",
       "      <td>4.230559</td>\n",
       "      <td>12190.202026</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>3.367468</td>\n",
       "      <td>3.572290</td>\n",
       "      <td>3.114934</td>\n",
       "      <td>8.06913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>189.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1928.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.788300</td>\n",
       "      <td>15428.000000</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2164.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.975800</td>\n",
       "      <td>20880.000000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>565.000000</td>\n",
       "      <td>1516.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.787900</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.166700</td>\n",
       "      <td>28200.000000</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>753.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.980000</td>\n",
       "      <td>5010.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>40.509000</td>\n",
       "      <td>96000.000000</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        hours   youngkids     oldkids         age  \\\n",
       "count  753.000000   753.000000  753.000000  753.000000  753.000000   \n",
       "mean   377.000000   740.576361    0.237716    1.353254   42.537849   \n",
       "std    217.516666   871.314216    0.523959    1.319874    8.072574   \n",
       "min      1.000000     0.000000    0.000000    0.000000   30.000000   \n",
       "25%    189.000000     0.000000    0.000000    0.000000   36.000000   \n",
       "50%    377.000000   288.000000    0.000000    1.000000   43.000000   \n",
       "75%    565.000000  1516.000000    0.000000    2.000000   49.000000   \n",
       "max    753.000000  4950.000000    3.000000    8.000000   60.000000   \n",
       "\n",
       "        education        wage     repwage       hhours        hage  \\\n",
       "count  753.000000  753.000000  753.000000   753.000000  753.000000   \n",
       "mean    12.286853    2.374565    1.849734  2267.270916   45.120850   \n",
       "std      2.280246    3.241829    2.419887   595.566649    8.058793   \n",
       "min      5.000000    0.000000    0.000000   175.000000   30.000000   \n",
       "25%     12.000000    0.000000    0.000000  1928.000000   38.000000   \n",
       "50%     12.000000    1.625000    0.000000  2164.000000   46.000000   \n",
       "75%     13.000000    3.787900    3.580000  2553.000000   52.000000   \n",
       "max     17.000000   25.000000    9.980000  5010.000000   60.000000   \n",
       "\n",
       "       heducation       hwage       fincome         tax  meducation  \\\n",
       "count  753.000000  753.000000    753.000000  753.000000  753.000000   \n",
       "mean    12.491368    7.482179  23080.594954    0.678863    9.250996   \n",
       "std      3.020804    4.230559  12190.202026    0.083496    3.367468   \n",
       "min      3.000000    0.412100   1500.000000    0.441500    0.000000   \n",
       "25%     11.000000    4.788300  15428.000000    0.621500    7.000000   \n",
       "50%     12.000000    6.975800  20880.000000    0.691500   10.000000   \n",
       "75%     15.000000    9.166700  28200.000000    0.721500   12.000000   \n",
       "max     17.000000   40.509000  96000.000000    0.941500   17.000000   \n",
       "\n",
       "       feducation       unemp  experience  \n",
       "count  753.000000  753.000000   753.00000  \n",
       "mean     8.808765    8.623506    10.63081  \n",
       "std      3.572290    3.114934     8.06913  \n",
       "min      0.000000    3.000000     0.00000  \n",
       "25%      7.000000    7.500000     4.00000  \n",
       "50%      7.000000    7.500000     9.00000  \n",
       "75%     12.000000   11.000000    15.00000  \n",
       "max     17.000000   14.000000    45.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSID1976.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'participation', 'hours', 'youngkids', 'oldkids', 'age',\n",
       "       'education', 'wage', 'repwage', 'hhours', 'hage', 'heducation', 'hwage',\n",
       "       'fincome', 'tax', 'meducation', 'feducation', 'unemp', 'city',\n",
       "       'experience', 'college', 'hcollege'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all column names\n",
    "PSID1976.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be looking at female labor supply of married women, so let's define a dataset that is just married women who are in the labor force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hours</th>\n",
       "      <th>youngkids</th>\n",
       "      <th>oldkids</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>wage</th>\n",
       "      <th>repwage</th>\n",
       "      <th>hhours</th>\n",
       "      <th>hage</th>\n",
       "      <th>heducation</th>\n",
       "      <th>hwage</th>\n",
       "      <th>fincome</th>\n",
       "      <th>tax</th>\n",
       "      <th>meducation</th>\n",
       "      <th>feducation</th>\n",
       "      <th>unemp</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>214.500000</td>\n",
       "      <td>1302.929907</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>1.350467</td>\n",
       "      <td>41.971963</td>\n",
       "      <td>12.658879</td>\n",
       "      <td>4.177682</td>\n",
       "      <td>3.185864</td>\n",
       "      <td>2233.464953</td>\n",
       "      <td>44.609813</td>\n",
       "      <td>12.612150</td>\n",
       "      <td>7.226226</td>\n",
       "      <td>24130.422897</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>9.516355</td>\n",
       "      <td>8.988318</td>\n",
       "      <td>8.545561</td>\n",
       "      <td>13.037383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>123.697211</td>\n",
       "      <td>776.274385</td>\n",
       "      <td>0.391923</td>\n",
       "      <td>1.315935</td>\n",
       "      <td>7.721084</td>\n",
       "      <td>2.285376</td>\n",
       "      <td>3.310282</td>\n",
       "      <td>2.439640</td>\n",
       "      <td>582.908769</td>\n",
       "      <td>7.950055</td>\n",
       "      <td>3.035163</td>\n",
       "      <td>3.571217</td>\n",
       "      <td>11671.255986</td>\n",
       "      <td>0.076936</td>\n",
       "      <td>3.308100</td>\n",
       "      <td>3.523405</td>\n",
       "      <td>3.033328</td>\n",
       "      <td>8.055923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>107.750000</td>\n",
       "      <td>609.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.262600</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.821750</td>\n",
       "      <td>16286.250000</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>214.500000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.481900</td>\n",
       "      <td>3.195000</td>\n",
       "      <td>2106.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.683100</td>\n",
       "      <td>21961.000000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>321.250000</td>\n",
       "      <td>1910.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.970750</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>2504.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.837775</td>\n",
       "      <td>29793.000000</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.980000</td>\n",
       "      <td>5010.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>26.578000</td>\n",
       "      <td>91044.000000</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        hours   youngkids     oldkids         age  \\\n",
       "count  428.000000   428.000000  428.000000  428.000000  428.000000   \n",
       "mean   214.500000  1302.929907    0.140187    1.350467   41.971963   \n",
       "std    123.697211   776.274385    0.391923    1.315935    7.721084   \n",
       "min      1.000000    12.000000    0.000000    0.000000   30.000000   \n",
       "25%    107.750000   609.500000    0.000000    0.000000   35.000000   \n",
       "50%    214.500000  1365.500000    0.000000    1.000000   42.000000   \n",
       "75%    321.250000  1910.500000    0.000000    2.000000   47.250000   \n",
       "max    428.000000  4950.000000    2.000000    8.000000   60.000000   \n",
       "\n",
       "        education        wage     repwage       hhours        hage  \\\n",
       "count  428.000000  428.000000  428.000000   428.000000  428.000000   \n",
       "mean    12.658879    4.177682    3.185864  2233.464953   44.609813   \n",
       "std      2.285376    3.310282    2.439640   582.908769    7.950055   \n",
       "min      5.000000    0.128200    0.000000   175.000000   30.000000   \n",
       "25%     12.000000    2.262600    1.420000  1920.000000   38.000000   \n",
       "50%     12.000000    3.481900    3.195000  2106.500000   45.000000   \n",
       "75%     14.000000    4.970750    4.550000  2504.000000   51.000000   \n",
       "max     17.000000   25.000000    9.980000  5010.000000   60.000000   \n",
       "\n",
       "       heducation       hwage       fincome         tax  meducation  \\\n",
       "count  428.000000  428.000000    428.000000  428.000000  428.000000   \n",
       "mean    12.612150    7.226226  24130.422897    0.668333    9.516355   \n",
       "std      3.035163    3.571217  11671.255986    0.076936    3.308100   \n",
       "min      4.000000    0.512800   2400.000000    0.441500    0.000000   \n",
       "25%     11.000000    4.821750  16286.250000    0.621500    7.000000   \n",
       "50%     12.000000    6.683100  21961.000000    0.691500   10.000000   \n",
       "75%     16.000000    8.837775  29793.000000    0.721500   12.000000   \n",
       "max     17.000000   26.578000  91044.000000    0.941500   17.000000   \n",
       "\n",
       "       feducation       unemp  experience  \n",
       "count  428.000000  428.000000  428.000000  \n",
       "mean     8.988318    8.545561   13.037383  \n",
       "std      3.523405    3.033328    8.055923  \n",
       "min      0.000000    3.000000    0.000000  \n",
       "25%      7.000000    7.500000    7.000000  \n",
       "50%      7.000000    7.500000   12.000000  \n",
       "75%     12.000000   11.000000   18.000000  \n",
       "max     17.000000   14.000000   38.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset data to just get those participating in the labor force\n",
    "df = PSID1976[PSID1976.participation == \"yes\"]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS\n",
    "\n",
    "We start with a simple OLS model estimating the impact of education and experience on log wages:\n",
    "\n",
    "$$ ln(wage_{i}) = \\alpha + \\beta_{1} education_i + \\beta_{2}experience_{i} + \\beta_{3} experience^{2}_{i} + \\varepsilon_i $$\n",
    "\n",
    "To estimate an OLS model in Python, use the [`statsmodels.formula.api`](https://www.statsmodels.org/stable/regression.html) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.157\n",
      "Model:                            OLS   Adj. R-squared:                  0.151\n",
      "Method:                 Least Squares   F-statistic:                     26.29\n",
      "Date:                Tue, 12 Oct 2021   Prob (F-statistic):           1.30e-15\n",
      "Time:                        10:17:01   Log-Likelihood:                -431.60\n",
      "No. Observations:                 428   AIC:                             871.2\n",
      "Df Residuals:                     424   BIC:                             887.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.5220      0.199     -2.628      0.009      -0.912      -0.132\n",
      "education                   0.1075      0.014      7.598      0.000       0.080       0.135\n",
      "experience                  0.0416      0.013      3.155      0.002       0.016       0.067\n",
      "np.power(experience, 2)    -0.0008      0.000     -2.063      0.040      -0.002   -3.82e-05\n",
      "==============================================================================\n",
      "Omnibus:                       77.792   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              300.917\n",
      "Skew:                          -0.753   Prob(JB):                     4.54e-66\n",
      "Kurtosis:                       6.822   Cond. No.                     2.21e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.21e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "wage_OLS = smf.ols(formula='np.log(wage) ~ education + experience + np.power(experience, 2)', data=df)\n",
    "# Estimate the model\n",
    "res = wage_OLS.fit()\n",
    "# Show the results\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HC0_se',\n",
       " 'HC1_se',\n",
       " 'HC2_se',\n",
       " 'HC3_se',\n",
       " '_HCCM',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abat_diagonal',\n",
       " '_cache',\n",
       " '_data_attr',\n",
       " '_data_in_cache',\n",
       " '_get_robustcov_results',\n",
       " '_is_nested',\n",
       " '_use_t',\n",
       " '_wexog_singular_values',\n",
       " 'aic',\n",
       " 'bic',\n",
       " 'bse',\n",
       " 'centered_tss',\n",
       " 'compare_f_test',\n",
       " 'compare_lm_test',\n",
       " 'compare_lr_test',\n",
       " 'condition_number',\n",
       " 'conf_int',\n",
       " 'conf_int_el',\n",
       " 'cov_HC0',\n",
       " 'cov_HC1',\n",
       " 'cov_HC2',\n",
       " 'cov_HC3',\n",
       " 'cov_kwds',\n",
       " 'cov_params',\n",
       " 'cov_type',\n",
       " 'df_model',\n",
       " 'df_resid',\n",
       " 'diagn',\n",
       " 'eigenvals',\n",
       " 'el_test',\n",
       " 'ess',\n",
       " 'f_pvalue',\n",
       " 'f_test',\n",
       " 'fittedvalues',\n",
       " 'fvalue',\n",
       " 'get_influence',\n",
       " 'get_prediction',\n",
       " 'get_robustcov_results',\n",
       " 'initialize',\n",
       " 'k_constant',\n",
       " 'llf',\n",
       " 'load',\n",
       " 'model',\n",
       " 'mse_model',\n",
       " 'mse_resid',\n",
       " 'mse_total',\n",
       " 'nobs',\n",
       " 'normalized_cov_params',\n",
       " 'outlier_test',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'pvalues',\n",
       " 'remove_data',\n",
       " 'resid',\n",
       " 'resid_pearson',\n",
       " 'rsquared',\n",
       " 'rsquared_adj',\n",
       " 'save',\n",
       " 'scale',\n",
       " 'ssr',\n",
       " 'summary',\n",
       " 'summary2',\n",
       " 't_test',\n",
       " 't_test_pairwise',\n",
       " 'tvalues',\n",
       " 'uncentered_tss',\n",
       " 'use_t',\n",
       " 'wald_test',\n",
       " 'wald_test_terms',\n",
       " 'wresid']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into the OLS Results object\n",
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                 -0.522041\n",
       "education                  0.107490\n",
       "experience                 0.041567\n",
       "np.power(experience, 2)   -0.000811\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the parameters\n",
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=array([[35.42844987]]), p=5.913982638501025e-15, df_denom=424, df_num=2>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run an f-test\n",
    "hypotheses = '(education = 0), (experience = 0)'\n",
    "res.f_test(hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3017661888741576e-15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or just get the f statistic/p-value for the test that all coeffs diff from zero\n",
    "res.f_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to adjust the standard errors (e.g., clutered, robust, etc), you can do that by changing a keyword arugment in the `fit` method that allows you to set the variance-covariance matrix used for the standard errors.  With this, we'll call the heteroskedastic robust VCV matrix function `HC1`.\n",
    "\n",
    "We won't use robust standard errors for these exercises, but to illustrate how this is done, suppose that we want robust standard errors for the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.157\n",
      "Model:                            OLS   Adj. R-squared:                  0.151\n",
      "Method:                 Least Squares   F-statistic:                     27.30\n",
      "Date:                Tue, 12 Oct 2021   Prob (F-statistic):           3.68e-16\n",
      "Time:                        10:22:26   Log-Likelihood:                -431.60\n",
      "No. Observations:                 428   AIC:                             871.2\n",
      "Df Residuals:                     424   BIC:                             887.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.5220      0.202     -2.589      0.010      -0.917      -0.127\n",
      "education                   0.1075      0.013      8.131      0.000       0.082       0.133\n",
      "experience                  0.0416      0.015      2.722      0.006       0.012       0.072\n",
      "np.power(experience, 2)    -0.0008      0.000     -1.931      0.053      -0.002    1.21e-05\n",
      "==============================================================================\n",
      "Omnibus:                       77.792   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              300.917\n",
      "Skew:                          -0.753   Prob(JB):                     4.54e-66\n",
      "Kurtosis:                       6.822   Cond. No.                     2.21e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "[2] The condition number is large, 2.21e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Compute robust standard errors using the HC1 method (same as Stata with \"robust\" option)\n",
    "# Estimate the model\n",
    "res = wage_OLS.fit(cov_type='HC1')\n",
    "# Show the results\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also estimate the linear model via a GMM estimator.  We should get the same coefficients, but the standard errors are computed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-GMM Estimation Summary                           \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                      0.1568\n",
      "Estimator:                     IV-GMM   Adj. R-squared:                 0.1509\n",
      "No. Observations:                 428   F-statistic:                    82.671\n",
      "Date:                Tue, Oct 12 2021   P-value (F-stat)                0.0000\n",
      "Time:                        10:23:21   Distribution:                  chi2(3)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                    \n",
      "===========================================================================================\n",
      "                         Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.5220     0.2007    -2.6010     0.0093     -0.9154     -0.1287\n",
      "experience                  0.0416     0.0152     2.7344     0.0063      0.0118      0.0714\n",
      "np.power(experience, 2)    -0.0008     0.0004    -1.9402     0.0524     -0.0016   8.276e-06\n",
      "education                   0.1075     0.0132     8.1697     0.0000      0.0817      0.1333\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason.debacker/anaconda3/lib/python3.7/site-packages/linearmodels/iv/data.py:25: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  if is_categorical(s):\n"
     ]
    }
   ],
   "source": [
    "wage_GMM = lm.IVGMM.from_formula(\n",
    "    'np.log(wage) ~ 1 + experience + np.power(experience, 2) + education',\n",
    "    df)\n",
    "# Estimate the model\n",
    "gmm_results = wage_GMM.fit()\n",
    "# Show the results\n",
    "print(gmm_results.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting regression results\n",
    "\n",
    "There are plotting capabilities built into the `statsmodels` objects.  Here, we'll illustrate one, a plot of fitted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEaCAYAAABARRODAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5Q0lEQVR4nO3dfZxVVb348c93HhHwgQDJNGdQE22QB8UQUAR8yGso1a0UR3+IXR8YSs3UupF183e5P1LxpimUlWhBmGmZerEkZihRSwYfUNBMdCDUq6gp8jzMfH9/7H2GMzPnHM6Zs/fa5+zzfb9e5wVn73P2Wntmzv6etfZa3yWqijHGGFOoyqKugDHGGJOJBSpjjDEFzQKVMcaYgmaByhhjTEGzQGWMMaagWaAyxhhT0CxQmUCIyBYROSzE4/+HiCwM4bh3ich/Bn3cUhXVz1NE1ojIBNflGjcsUJmciEiLiGz3A1Pi8TFV7auqr/qv6Xax8t93ajS1NnGS6u9LVetUdXlEVTIhs0BleuIsPzAlHm9EXaFSJCIVUdfBGBcsUJlAiIiKyBEicglQD1zrt7YeEpFfAIcCD/nbrvXfc4KIPCEi74vIc8ldNyIyWET+JCIfishSYECGsl8UkclJzytE5B0ROdZ//msR+V8R+UBE/iwidWmOc6GIrEh1Xv7/q0XkJhHZICJviciPRGQff98AEXnYP5f3ROQxEen2+fLfc1OXbb8Tkav8/39MRO4XkU0i8pqIXJ70uv8QkftEZKGIbAYuFJFPiUiziGz263Sz/9oJIrKxSzkdrdp070vzc5ksIs/65/aEiAxL2jdSRJ72f0+/Anrl8PPcR0Tmish6/3ezIunnmfJ3lurvK8W5VYvID0TkDf/xAxGpTv65iMjXReRtEXlTRKanO3dTGCxQmUCp6h3AIuAGv7V1lqpeAGxgT0vsBhE5GPgf4D+BjwBXA/eLyED/UL8EVuEFqP8LTMtQ7GJgatLzTwPvqOrT/vNHgE8ABwJP+/Xrie8DRwIjgCOAg4Hv+Pu+DmwEBgKDgG8BqfKT/RI4R0QEQET6AacD9/iB7SHgOf/YpwBXisink94/BbgPOMA/j1uAW1R1P+Bw4N4szyWr9/nB/k7gUqA/8GPgQT8YVAEPAL/A+x3+GvjXLMsHuAk4Dhjrv/9aoN3fl/J3lurvK8VxZwEn4P2ehgOfAr6dtP+jwP54P+MvA7f7vwdToCxQmZ54wP92/b6IPNDDY5wPLFHVJararqpLgWbgTBE5FDgeuE5Vd6rqn/Eu4On8EjhbRHr7z8/ztwGgqneq6oequhP4D2C4iOyfS2X9wHIx8DVVfU9VPwT+CzjXf0krcBBQo6qtqvqYpk6k+RheADvJf/4F4Em/+/R4YKCqXq+qu/x7fj9JKgP/tQ/4P7PtfrlHiMgAVd2iqn/J8pSyfd/FwI9V9a+q2qaqdwM78QLBCUAl8AP/nO8DVmZTuB+ULwKuUNXX/WM/4f+O8v2d1QPXq+rbqroJ+B5wQZdzv96v8xJgCzAky2ObCFigMj3xWVU9wH98tofHqAG+mBTw3gdOxLvYfwz4p6puTXr9+nQHUtVXgBeBs/xgdTZ+oBKRchGZIyLr/O6yFv9tabsS0xgI9AZWJdX39/52gBuBV4BHReRVEflmmroqcA97WoDnsaeFVwN8rMvP5Ft4LbSEf3Q55JfxWnkvichKSeoC3Yts31cDfL1LnT6O9zv6GPB6l4Cc9vfUxQC8bsJ1XXcE8Dv7WJd6rPe3JbyrqruTnm8D+mZ5bBMBuxlrwpCqJdF12z+AX6jqxV1fKCI1QD8R6ZMUrA5Nc9yERPdfGbDWD17gBYIpwKl4F7z9gX8CkuIYW/GCUaIeH03a9w6wHahT1de7nZzXwvo63kW9DmgSkZWquixNXR8VkTnAaOBz/vZ/AK+p6icynGenn4Gq/h2Y6rdQPg/cJyL9U5xLOXuCatr3dflykKjTbFWd3bUiInIycLCISFKwOpQ9wWdvP88deN2Oz3U59N5+Z3tb8uENvAC7JqlONuCniFmLyoThLaDrnKqu2xbitYA+7X+D7uXf6D5EVdfjdQN+T0SqROREINW9iGT34N3rmUFStx+wL15X1bt4F83/ynCM54A6ERkhIr3wupwAUNV2vG64/xaRAwFE5ODE/SN/wMERfhfhZqDNf3Sjqs8Am4CfAn9Q1ff9XU8Bm0XkG/5Ag3IRGSoix6ersIicLyID/foljtMGvAz0EpHPiEgl3j2a6ize19VPgMtEZLR4+vjH3Bd4EtgNXC7eAJbP490PyvbneSdws3gDSMpFZIw/6GFvv7NUf1/JFgPfFpGBIjIA7z5i4HPwjDsWqEwYfgZ8sss9rP+Hd/F4X0SuVtV/4H1r/hbeRfsfwDXs+Zs8D6+18R7wXeDnmQpU1TfxLpxjgV8l7fo5XtfP68BaIO09HFV9Gbge+CPwd2BFl5d8A6977y9+l9Qf2XNv4xP+8y1+PebtZV7PYrwWQ/K9tDa8gDwCeA2v1fFTvBZFOmcAa0RkC94AiXNVdYeqfgA0+O9/Ha91s3Fv7+t6cFVtxrtPdRteq+YV4EJ/3y681tiF/r5zgN8kvXdvP8+rgefx7mu9hzdYpYy9/85S/X0l+0+8Lzqr/eM/7W8zRUps4URjjDGFzFpUxhhjCpoFKmOMMQXNApUxxpiCZoHKGGNMQbNAZYwxpqAV1YTfAQMGaG1tbdTVMMYYE7BVq1a9o6oDU+0rqkBVW1tLc3Nz1NUwxhgTMBFJm37Luv6MMcYUNAtUxhhjCpoFKmOMMQWtqO5RpdLa2srGjRvZsaNbmjITkV69enHIIYdQWVkZdVWMMTFQ9IFq48aN7LvvvtTW1uIvmmoipKq8++67bNy4kcGDB0ddHWNMDBR919+OHTvo37+/BakCISL079/fWrhFpqEBKipAxPu3oSHqGhmzR9G3qAALUgXGfh/FpaEB5s/f87ytbc/zefOiqZMxyYq+RVXsWlpaGDp0aI/fr6pMmjSJzZs3B1irvXv++ee58MILnZZpwnHHHbltN8a1kgtUixZBbS2UlXn/LloUdY3ys2TJEoYPH85+++3ntNxjjjmGjRs3smHDBqflmuC1pVyHOP12Y1wrqUC1aBFccgmsXw+q3r+XXJJ/sGppaeHoo4/m4osvpq6ujtNPP53t27czYcIErrzySsaOHcvQoUN56qmnMh5nx44dTJ8+nWOOOYaRI0fS1NQEwLZt2/jSl77EsGHDOOeccxg9enRHho5FixYxZcoUAG644QZuvfVWAL72ta8xadIkAJYtW8b5558PwIwZMxg1ahR1dXV897vf7Sh7yZIlHHXUUZx44olcfvnlTJ48GYCtW7dy0UUXcfzxxzNy5Eh+97vfdbznrLPO4p577snvh2eMKVquvviXVKCaNQu2beu8bds2b3u+/v73vzNz5kzWrFnDAQccwP333w94F/onnniCefPmcdFFF2U8xu233w543WqLFy9m2rRp7Nixg3nz5tGvXz9Wr17Nddddx6pVqzre8/jjj3PccccBMH78eB577DEAmpub2bJlC62traxYsYKTTjoJgNmzZ9Pc3Mzq1av505/+xOrVq9mxYweXXnopjzzyCCtWrGDTpk0dx589ezaTJk1i5cqVNDU1cc0117B161YARo0a1VGeMaa0hPXFP5WSClTpeqmC6L0aPHgwI0aMAOC4446jpaUFgKlTpwJeENm8eTPvv/9+2mOsWLGCCy64AICjjjqKmpoaXn75ZVasWMG5554LwNChQxk2bFjHe9577z323XffjnJXrVrFhx9+SHV1NWPGjKG5uZnHHnusI1Dde++9HHvssYwcOZI1a9awdu1aXnrpJQ477LCO4eSJOgM8+uijzJkzhxEjRjBhwgR27NjR0d134IEH8sYbb+T5kzNRq6nJbbspXC5vbYT5xb+rWIz6y9ahh3pRP9X2fFVXV3f8v7y8nO3btwPdR8BlGhGnqjltB6ioqKC9vZ2ysjIqKyupra1lwYIFjB07lmHDhtHU1MS6des4+uijee2117jppptYuXIl/fr148ILL2THjh0Zj6+q3H///QwZMqTbvh07drDPPvukfa8pDrNne9+Eky86vXt7203xSLRwEr/HRAsHoL4++PLC/OLfVWQtKhHpJSJPichzIrJGRL4XdpmzZ3sfwGRhfyB/9atfAV5raf/992f//fdP+9rx48ezyP8K9PLLL7NhwwaGDBnCiSeeyL333gvA2rVref755zveM2TIEF599dVOx7jpppsYP348J510Ej/60Y8YMWIEIsLmzZvp06cP+++/P2+99RaPPPII4LXeXn311Y5WYKLOAJ/+9Kf54Q9/2BHMnnnmmY59L7/8cl4jFk1hqK/3RvjV1HjzqGpqvOdhXNxMeFy2cCD9F/wgvvh3FWXX305gkqoOB0YAZ4jICWEWGMUHsl+/fowdO5bLLruMn/3sZ4B3/+jf/u3fur22oaGBtrY2jjnmGM455xzuuusuqquraWhoYNOmTQwbNozvf//7DBs2rCPgfeYzn2H58uUdxzjppJN48803GTNmDIMGDaJXr14d3X7Dhw9n5MiR1NXVcdFFFzFu3DgA9tlnH+bNm8cZZ5zBiSeeyKBBgzqOf91119Ha2sqwYcMYOnQo1113XUdZTU1NfOYznwnl52bcqq+HlhZob/f+tSBVfFy2cMDxF39VjfwB9AaeBkZnet1xxx2nXa1du7bbtkJx8skn68qVK/M+zu7du3X79u2qqvrKK69oTU2N7ty5U1VV33jjDT311FPzLuPDDz9UVdX29nadMWOG3nzzzRlfv2PHDh09erS2tram3F/Ivxdj4qimRtUb1tD5UVMTXpkLFybKbdOaGu95TwHNmubaH+lgChEpF5FngbeBpar61xSvuUREmkWkOXk0WinZtm0bJ554IsOHD+dzn/sc8+fPp6qqCoCDDjqIiy++OO8Jvz/5yU8YMWIEdXV1fPDBB1x66aUZX79hwwbmzJlDRUVJ3eY0pmBFcWsj0RKH8lBb4qIZbqS7IiIHAL8FvqqqL6R73ahRo7TrCr8vvvgiRx99dLgVNDmz30vPLVrk3VfYsMHr758927riTHYSfzvr17dTU1Pm7G9HRDIOysryGKtUdVSqfQUxPF1V3weWA2dEWxNjouVybkrXcuOUsaVUuWrhuBblqL+BfksKEdkHOBV4Kar6GFMIXI/cguiCozHZirJFdRDQJCKrgZV496gejrA+xkTO9cgtiCY4GpOLyAKVqq5W1ZGqOkxVh6rq9VHVxZhC4XJuSkIUwbGUzJw5M+oqFL2CuEflXFOT1xHvJ33N16233srRRx9Nv379mDNnDgAPPPAAa9eu7XjNXXfdlXO6oXyXADHFJ4qRW1EEx1Jy3333RV2Fold6gaqpCSZP9jriJ08OJFjNmzePJUuW8M9//pNvfvObQDCBypSeKCalRxEco/Txj3/caXlxXu06MQgH2sIdhJNuglUhPvKe8NvYqNq7d+fZcL17e9t76NJLL9XKykodOnSo3nzzzTpz5kx9/PHHtV+/flpbW6vDhw/XOXPmaJ8+ffTII4/U4cOH67Zt27S5uVnHjx+vxx57rJ5++un6xhtvqKpqc3OzDhs2TE844QS9+uqrta6ursd1i5JN+C0uiYmbIpr3xM1C51323KmqqnJanqqbc1y4MPXltKd/O2SY8Bt58MnlkVegShWkAgpWNTU1umnTJl2wYIHOnDlTVVWnTZumv/71rztek5ylYteuXTpmzBh9++23VVX1nnvu0enTp6uq6jHHHKPLly9XVbVAZUwIXAeqiooKp+WpujnHoDNhZApUpZNWYPr07kObErZt8/b7SVnD9re//Y0XXniB0047DYC2tjYOOuggPvjgA95//31OPvlkAC644IKOxLHGmOLUFtOlklOtRJFpez5KJ1AtWODdk0oVrHr39vY7oqrU1dXx5JNPdtr+/vvvZ1wGxJi4Oe2001i6dGnU1TA9UF4OqWJweXnwZZXOYIqJE+Hhh1PfNX74YW9/gPbdd18+/PDDlM+HDBnCpk2bOgJVa2trx8rA+++/PytWrADoWPLDmLhqbGyMugqh0wJIUxeGdA3FMBqQpROooHuwCilIAZx77rnceOONjBw5knXr1nHhhRdy2WWXMWLECNra2rjvvvv4xje+wfDhwxkxYgRPPPEEAAsWLGDmzJmMGTPGFiU0sdfe3h51FUwP9e+f2/Z8FERS2mwFlpS2qcm7J7VgQShBylhSWpOdIJKZFnqZcT3HAQPg3Xe7b+/fH955J/fjZUpKWzr3qJJNnOhs4IQxxSSKi6opTu+9l9v2fJRW158xxphAlMpS9MaYAuEsw4CJjdmzwV+/tUNVVTgZTWLR9aeqNqy7gFjXUXFJLPPhzdwo61jmA+KznpEJR9ePelgf/aJvUfXq1Yt3333XLo4FQlV599136dWrV9RVKXq//OUvnZRjy3yYnpg1C1pbO29rbQ3n76boR/21traycePGWCd+LDa9evXikEMOobKyMuqqFLWuc/HCUlaW+puwCIQ9ejyuI+KiLM9VmUH/3cR61F9lZSWDBw+OuhrGBG7Lli1Oyjn00NRpb2yZD5OJy7+bou/6M8bkp9SW+TDBOPPM3LbnwwKVMVlKJBGOm+Q1sKDdyRpYUbCRjcG6997ctuej6Lv+jHGlKaAVoY17NrIxeKmyUmTang9rURmTpbjmpUtcxL37DXsu4mG2OFy3bmxkY3GzQGVMlopphGwuXF/EowiMLtdOilJcuzctUJmiNHPmzKirEBuuL+JRtG7SrZEUxtpJUYniC4ArRT+PypSmqqoqdu3a5bTMuM6/qahIvwDe7t3BlxfFvK1MiWvC/hG7+j3W1qb+clFTE04O7qB/ppnmUVmLyhSl1q5T4k2PuVwAD9wmM03wRjRmv70YuW4Zl6WJHum251VW8Ic0xhQT1xfx2bOha9KSyspw5225nPMTFdfdm+lav2G0ii1QmUC4yksXhbjeoE6IYsJv126jsHNKL1mS2/Zi5LplnO53Fsbv0gKVCcTixYujrkIo4nyDOqG+HqZNS3zzVsrLvedhzS+aNQu63l7ctSvcwRSlMOqvb9/ctucr3X2oMG7HWaAygXj99dejrkIoSmH+zaJF8NOfJr55C21t3vOwgvGGDbltD0IpjPrbujW37cXEApUJxLp166KuQihK4Zv4FVekXq7hiivCKS+KwRSuu8Wi4LKF41pkgUpEPi4iTSLyooisEZGQPhbGhbgus1IK38RdpsKBaO6JlcKovziLskW1G/i6qh4NnADMFJFPRlgfY7ophW/irkWRBNflsumloiQGU6jqm6r6tP//D4EXgYOjqo/JT1tMr9z2TTwc9fWJSajltLS4SQzratn0UlFygylEpBYYCfw1xb5LRKRZRJo3bdrkvG4mO3ENVKWwVpPr0WIQTVJaV8umm+BFHqhEpC9wP3Clqm7uul9V71DVUao6auDAge4rGADXc4ziPKfJtVJYq6m6Orft+bKktOFw2RXnWqS5/kSkEngY+IOq3ry31xdrrr+zzjqLhx56yFl5xx57LE8//bSz8iC+efCiLNNVea7z4LnOSQelkevP9TmWRK4/ERHgZ8CL2QQpk724zmky8RDFPCoTnnUMph1hHYNDKyPKrr9xwAXAJBF51n/EKPPWHhY4jNkjinlUpTDNoH//3LYHYR2DGUwLAgymJbRgFeWovxWqKqo6TFVH+I8YZd7aI66TYY3piSgGqEyYkNv2YvSlL+W2PV/JQQoINVhFPpiiFMR1MqwxPVFfD2PGJJ55NzPGjAl3gMorr+S2vRjde29u2/MyuHOQSkgEKwYHG6wsUBljnGpogGXLEs+8S92yZd72sJTCfbFEJpHfMoV2hN8ypdP2QLV0D1IJ4u8PkgUqY4xTd9yR2/YgRHFfLIrlYX7LFKbwIAJM4cGOYFXsLFAZY5yKIi2V64UTo5grlhykgHCD1d5mgwc8W9wClTEm9lwvnOh8eZgpnYNUQiJYMSXgYLV9e377c2SByhSVuK+2a8Lh+h6V80wYD3YPUgni7w/U3pq/ATePLVCZolEKq+2acLi+RxXndEbA3iegBTxBzQKVKRqlsNpuKYjiIu567lYihdAEmniNWibQ1Gl70SvbS+jY2/5ciwv0aEXAErYWr6iGGFt3Y7AmTcptexCiSC48gSYe4V+oZT2P8C8dwSoWuqaiz3V/jkouUC1evDjqKsSKy4t4VEOMXXc3xj0wRjX59vHHYeH6cbRTzsL143j88fDKSgSpXuwEoBc74xesXFLVonkcd9xxmq/JkyfnfYxcVVVVOS3vwAMPdFLOwoWqvXureh0a3qN3b297WOVVVXUur6oqvPJUVWtqOpeXeNTUhFPewoWqlZWdy6qsDPccU51f4hEGkdRliYRTnqrqjBmqjzFW2/3C2kEfY6zOmBFCYY2Nup3qlCe5nWrVxsbgy+zbt+Pcuj7aQbVv32DLy/RH08M/HqBZ01z7S65FZYITxT0j16u0uh69dcUVqRf4u+KKcMqLQhQt4/Pmj2McT3SaYzSOJzhv/rjgC5s6taMl1VUvdsLUqcGXuWVL5lF/W7YEX6ZDFqhMj7m+ZxTFKq2us26nS3cTShqciMyeDZWVnbdVVoaYlHZc5yCVkAhWjAs4WO3ald9+040FKtNjrr8ZRzGYIoosCqVABG6jgXaE22gId9j2E92DVEc9/P2BqqrKb38xmDGDdJ0Z6u8PkgUq02Ouh/xG0WXkjRLLfnu+0mWeCTgjTaRmzYKbdzXQwHwEaGA+N+9qiM80g2uvzW9/MfjiF9mdJnzspgy++MVAi7NAFSOJ0WJvv/2mk9Firof8RrGOkesccenuucVm/g1w7fo9QQroCFbXrg8xfbpLt96a3/5iMHUqlbSn3FVJe+D34SxQxUQpZG2IYi6M6xxxW7fmtr3oNDQwIylIJQgwg/nhrvXhyuWX57e/J3r1ym9/oUs3HLAQHzY8PT3Xw6hV3Q9PT0ZYY6e7leN26Lbr8pLL3O0PZd4N4ZUZwrDmgitz0KDMZQ0aFGx5qqpz52Yenj53bsGXhw1Pj78oBhqUQkoj16P+orIboQyvZVPmPzdF5IYbMg8YueGGoi5vr4FKRA4RkatF5HcislJE/iwi80TkMyJiga5ARDHQoBRWTXU96q9//9y2ByE5SEHIwarruPRc9/dEdXV++3O1eHH6Y1ZXe/uDtre+4SLvO84YaERkAXAnsAv4PjAVaAD+CJwBrBCR8WFX0uxdFAMNPvKR3Labvbvllu6ttfJyb3sopHOQ6tiMf3EIety44xxxAOxMPfk26/25mjgRHnmke7Cqrva2T5wYbHnQvWsj1/25WryY7aQOxtsJPhjvrUU0V1VPV9VbVfUJVX1FVV9Q1d+o6leBCcAbgdbI9EgUAw3Sfb6D/tyXmrKyzlm3A05E3U3GLpygRXHTf2/BNoxJXF2DVZhBCuDGGzPPa7rxxmDLmziRM3mkW7DaTjVnEsJ5prt51fUB7AMMyfb1YTxsMEV2XOX6i+LG/56y3QymKC9PfX7l5eGUV1OjOoFGbaVMFbSVMp1AY3iDYlwPNOjbN3NZQeekU1Wtq8t847+uLvgyExob9TUIJ79fF1fSfYBDO+iVBDyQwte/v/e3us3Pa7iNap1Ao/bv37Pjke9gChE5G3gW+L3/fISIBLxkpDGFZ8KE3Lbn67D1TSzlVCr8OSoVtLOUUzlsfVM4BboWxb2UNWsytxrXrAm+zISJExns/xu2H3AVVzG3o2WlwFXM5QdcFUp5t9wCj1d6LasWajiTR3i8cmIo3dTZdip8F/gU8D6Aqj4L1AZfHVNM+vTJbXsxcrokRVPnIJWQCFY0xSBYHXBAfvt7YuzYzN1iY8cGX2ZEEsFqN+WhBinwbissWACv1UxkMK/yWs1EFiwI53ZDtoFqt6p+EHzxppilu51Q7HMLkyVGMCbnpUveHqgzz6Q8zWz/ctrDS4fh0re/nTlofPvbwZe5bl3mFtW6dcGXGYHEF8QfcBWV7O4IUmF+cayvh5YWgHJaWsK7J55toHpBRM4DykXkEyLyQyDgTI6m2Lz3Xm7bi9Ghh3pBKjkv3W00hDPsf8eO/PYXg1tvzRw04pBeKCL/5//ktj0Irhb5zDZQfRWoA3YCi4HNwJXhVMkUiyjmbrl2d9/Ueenu7huDVD9RWLCAXaSeK7WLSq8vKWiLF9NWkXoodVtFSPOaIuA63ZfLtG1ZBSpV3aaqs1T1eFUd5f8/Bl/vTD6imLvlVEMD49ekzks3fk0IeelK4V7KM89QSeq5UpW0wjPPBF/mxImc3/8RdnYJkDup5Pz+IQ4Zd8z1Ip8uM9NkO+rvIRF5sMvjFyJyhYj0+I6EiNwpIm+LyAs9PYaJTn09TJuWmKCqlJd7z8Ocu+XU/O5BKkH8/YFyvW5SFK69NvM5hrQExltvQddBzkoZb70VSnGRcJ3uy2Vmmmy7/l4FtgA/8R+bgbeAI/3nPXUXXoYLU4QWLYK7706kExLa2rznYWZsb2iAedJAO96/oSbb3mef/PbnyvFidJ2OncP2vAwYkLm8AQOCL7OpiYeZ3G15+F7s5GEmx2M0Je7Tfbns+s82UI1U1fNU9SH/cT7wKVWdCRzb08JV9c9AjG69lxbXSWkbGqBu/p5lImYwn7r5IQar/fbLb3+ujjgiv/095DQzxVtvZS4vjCbO9On0JnUKod5sg+nTgy8zAq4X+XTZ9Z9toBooIh1x0v9/4qvPrsBrlURELhGRZhFp3rRpU5hFmRy5Tko7dH7qgQ1D54cUqUaPzvztf/ToYMu75prMF/Frrgm2vCjU1WX+mdbVBV/m5ZdnLjOM9aEi4HqRT5dp27INVF/HS0DbJCLLgceAa0SkD3B38NXaQ1Xv8AdwjBo4cGCYRZkcJZr4yXnpkrcHKooF9x58MHPgeDDg5CwVFfntLwbj95LDem/7eyKiIfGuhm4nuB71B+7mUeWS668aGA6MAHpl+74sjlsLvJDNay3XX3Zc5fqbMcPL9bUFb/XELfTWCTTqjBkhFFYKC+7ZOYZzjo2Nur2sd8qytpf1DiUPXxSLihZ77k0CWjjxE8AQYBjwJREJcRqZKQb//I13k7qP3//fh208zGT++Zt43Jx2num7b9/89heDs8/O3A139tnBlzlxIpN5mK10vqGyld5M5uFQhqdHsahonBf5zHZ4+neBH/qPicANQN5/USKyGHgSGCIiG0Xky/ke0zjS1MRP39oTpBL6sI2fvhXCSKq5czNf4ObODbY8cL+O0YMP0krqq0or5cF3Nfqcjvp77rnM3XDPPRdGqSxr7xysEkFqWXs4c6iiWFTU9ag/l7JtUX0BOAX4X1WdjtcFmPeymKo6VVUPUtVKVT1EVX+W7zGNI9OndwtSCX3CGEk1ciStaTIatFIJI0cGWx64T6A6cSJ3cEm3AKHAHVwS2sRUp6P+Fizo1rJJ2ErvcDJT4LUqluMFqxZqmMzDLGdiaK2NKLK2lHyLCtiuqu3AbhHZD3gbOCy8apmCt2ABbeWpA0dbeQipcKZPpypNRoMqWsMZYuw6gerNN3ca1ZiQGN3IzTcHW14UIuiGgz3LsixnIoNpYTkTO20PWhRZW6xFBc0icgDe5N5VwNPAU2FVyhSBZ56hvC114ChvCyEVThRDjF2PFosia0Pfvpl/riHcF3u+f+puuOf7h5fKyOlyLUSz4rbreVROpRtlke6BN0pvWK7vC+KRz6i/hQu91VOhTWtqwh1901UsR/2lW/o28Qh6CVzvl5f+EcYSuHO7r5iaeLSD6tyAV051XZ5qJKPwFi5Uraz0Roy+Ro1OoFErK8P9TIqkPjWR8MpMwMWwO/VG4aY6x1BG4XYRxDkSwAq/PxeRi0XkKFVtUdXVoUXOELjM8pusocGb+rJr1w4qKsKZ6tNNUxPN77wTflqYG27Ib3+uSqFFVSJcLriXUAqZ/qOYR+VMugiW/AAmAd8BlgLrgPuBK7J5b5CPnrao0n0ZD+NLeELi203yt8bQv900NqpWV3sFV1eHMj8kuaw2KUv5g22TsuDLjqJF1diou8srU5a3u7wy+HN03UpVVZ0xI3MrLuSv4zhqbUQxrynB1TnGeR5V1kECKAdOAP4dWA+8lO17g3r0NFBF0ewvL089GTaMa42qdg5SiUeYwapfv8yfjH79gi2vsVF3V1SnLGt3RUjnOXdu5nOMQ9efqt5G92DVDnob4fcZubqIq0bX/W+BKutj5BeogGXAX4D/Bj4PHJjN+4J+FFOLKjlIJR6JYBW4VEEq7GBVlro11fEoKwu2vCjO0XULp7FRd5K6BbeTEFpwPugcrBJBqlgucIVepgWqrI+Rd2aK1XjJZ4fiZaYYKiIBr3EQHudDRZs6Z2xISGRuCPz+0dSp6Sef7tzp7Q/ajTdmvmd0443Bljd9euZzDGN4+iXd5zQlqL8/UFEMwfd9hXnMw1tmZB4z+ArzQivLhCPO86hyatEAffGWpV8P7MzlvUE8imbUn+v7KYMGZS5v0KBgy/O9dErqLqOXTgmhy6ixsftNhsSjdzj52pz/Hhu7t8KTW+NhtqhcfxOfMSPRYG3X8nI3I9Pi3vUXxai/IH+mBND19xXgV8AreN2A3wUmZfPeIB9Fk5TW9UU1im6xxkZtrUp9jq1V4VxUl36rUbfT+Ty3U61LvxXSfbgIBhpM2S91l/GU/cIbGOM6UEV1Qa3s0qsa9pD4BFeBStXtF4CgB6gEEaiuAUYDFdm8PqxH0QQqVfefRteDKSIYhXfuoEbd1iVQbaNazx0U0jlGMApv4ULVSdJ5EM4kaYxV1u10P9bQBhqpav/+qcvs3z+8MhNcBiqXrcag7/33OFABfTPtz/Y1QT2KJlC5Hi2W4Hh4utNuqii6xSIYhbdwoWpVVedpDVVV8VoewnV5UZW5p2w3gcr1EPygR1PnE6iWAXOB8UCfpO2HAV8G/gB8IdMxgnwUTaCKYj5MQmOjbigLYR5TCtf3634hbwe9vl8IgTiKeVSq2nxe6nNsPi+cLxtRjFC1QBUuV4HK9d+OyxZVxlF/qnqKH6wuBdaIyGYReRdYCHwUmKaq9/V8KEdMuc7akGziREYNGBBacs8OTU18c/O3UiZQ/ebmbwU/sjGi5cT/9fGruIo9S4wocBVz+dfHrwqlPC97SvbbTXb6989tezFyvbSI09HU6SJYIT6KpkWlmr77L6xuvyROcv25HmkYUYsq0b1xJXO1lXK9krl5dW9kW15Q3SnZcN3aiKLVmOhSTS4v7C7VBGLaolItvFF/x6Z4HI7jwRVFFahUuwcrB0FKNaaBqrFRt0rqe1RbJbyh264//KXQLRbVCLy4D08v9jRRmQJVthN+5+FlprgDb6mPJ4F7gJdF5PTg2ncha2rip8uWhZ+wNeGqq2DuXHaDtwLtVeF0F0Vi9OjMXXGjRwdb3sSJPPHvqdcxeuLfw1vHKIp1hUqBSObnYaivh5YWgHJaWsJNghuFKJYWcSZdBEt+4AWluqTnnwQW4A2qeDabYwTxyKtFlTy3KawJomnEcpmPTF/DQ/w6vvRbe1pWW6V3eHOokrj8Jh7FMOqKitRlVlSEU14UXVTJcNTCiaq8KMoMojwCaFEdpaprkoLbWmCkqr4aWMQMU1MTTJ4M2/yURtu2ec9dtaziaMaM/Pb30KmzJ9J72cO0AL2XPcyps0MeNILbb+K33NI95U15ubc9LNXVuW3Plw0YMbnKNlD9TUTmi8jJ/mMeXrdfNaRJTlYougapBAtW+Zk3L30wmjHD2x+WiRMZ7P8bR6kCVZi2bs1te75inZPOhCLbQHUhXvqkK4GvAa/621qBwr5aTJ/ePUglbNsWaqLP2EsVrMIOUjE3axbs2tV5265d3va4aGvLbbsxWQUqVd0O/BBv8cRvA7eo6jZVbVfVLWFWMG8LFnS/G57Qu7e33/TYonHz+HlfL+v2z/vOYNG4+AWpRYugthagjdracFeGdj0XBqAszVUg3fZ8eTf7s98eFJe/RxOwdDevkh/ABLyM6X8C/gy8BozP5r1BPno8mCJVkliHAypiOZhCoxkO63qIsev5N6WQmSKqv5tiHrpd6GUGUR4BzKNaBQxJen4ksCqb9wb5sFF/mbm+iLu+qEZxsXE9Ci+Kc0y3BmbQa18mi/vfajILVFkfI+9AtTqbbWE/8p7w29io/7vPPk6DlKqbQBXFBc51FoVSaG2our+IR3GOe8p2c0GNIuPHnrIdFNJF3AKVePszE5E7AQV+4W+qx8tK4XQkwqhRo7S5uTmvY5x11lk89NBDAdUoO9XV1exMtzptQGprUw/vralJDK0u/jLLyrzLS1ci0N4efHmJY6eTxUcnz7KFbD6f+ZeTfl9czjGKz0dCRUUFu3fvDreQLlz9XIMsT0RWqeqoVPuyvV06A1gDXA5cAawFLsurViZQUdyEd5214dBDc9sehCiSmdpN/+CdeWZu24NUXgLj7iXk1CLZjvrbqao3q+rnVfVzqvrfqhpuE8HkJIqLuOuULVGkM7rlFqis7LytsjK8CbiLFsEllyS+/Zexfr333IJVfpYsyW17kHr16hV+IRELOxhnDFQi8ryIrE73CLVmJidR5aRzmbUhilxm9fXeDIbkMhcsCK/MWbNSz02P0zyqKETR45BQCoGqLKy5DInj72X/ZOCsDI+8iMgZIvI3EXlFRL6Z7/FKWawTUiaJIrGoyzKjvKDGWRQ9Doku3LfffjP2XbhhB+OKTDtVNbTsWyJSDtwOnAZsBFaKyIPq5RE0PVBf7z0GDTqIlpa3oq6O6YFDD0190z/MC2opOOKI1D/XI44Ip7xEF67XOt7ThQtuvlxVVGS8tAfu8MMPD/X4PW6vicgdeZb9KeAVVX1VVXfhZWifkucxjSlqUXTh9umT2/ZitHx5btvzFXUXbu902XhCcvDBB4d6/Hw6Fn+cZ9kHA/9Ier7R39aJiFwiIs0i0rxp06Y8izSmsEXRhes6KW0UXOcXjLoL1/V9salTp4Z6/JwClYjsJyL7AqjqqjzLTjWesdtAfFW9Q1VHqeqogQMH5lmkMYXP9X24Ushm7voco7gnluwLX/iCm4J85513XqjHzypQicgoEXkeWA28ICLPichxeZa9Efh40vNDgDfyPKYxJkelkM08cX8o2+35inpl6Ntvv91NQY5k26K6E2hQ1VpVrQFm4q3wm4+VwCdEZLCIVAHnAg/mecyCkhj1s2vX9tiP+jHFK6ps5i4lVqTxWlBKeXm4K9Ikd+GKENtRuK5kG6g+VNXHEk9UdQXwYT4Fq+pu4CvAH4AXgXs1aRXhYmcTN02xiPrbvyvz5oGXyaiM3bvDXzYt0YXb3o6zqRRxlW2gekpEfiwiE5JW+F0uIseKyLE9LVxVl6jqkap6uKrG6mMR9agfY7JVXw/TpnVubUybFt8Lq+uh2yZ/2f7GRvj/fsf/V/AGPoz1/50UbLWKX9SjfozJ1qJFcPfdiXtSQlub93zcuHgGK9dDt03+sg1U/wL8K1Cb9B5V1evDqFQc2MRNUywytf7jGKhKIaVR3GTb9fcAXsqkVmBL0sOkUSr9/qb4WevfFLpsW1SHqOoZodYkZhLfRGfNgvXr26mpKWP27Hh+QzXFzVr/ptBl26J6QkSOCbUmMZQY9VNVtY+N+jEFa/bs1EuZWOvfFIpsW1QnAheKyGvATvzBFKo6LLSaGWOc6bruXcjr4BmTk1wGUxhjYmjWLNi1q/O2XbvcDKYIe2XYVMJOoGqCl1WgCnO5D2NMtEptMIUFquIT7rKMJvYSaaKgzdJEFamPfCS37UHq379/+IV0EXam71KS+PyXlRHq59+maJsei3pxOFP8TjjhBOdlhp3pu1R0/vwT6uffWlSmxyxNVDy8915u24NkrZvi5fLzb4HK9Fip3duIqyjXTrLWTfFy+fm3QGV6LOrF4UwwLIuK6QmXn38LVKbH7AIXD8lrJ0G7rZ1ksuLy82+ByvSYXeDCVVbm7uOZyKIiUmFZVExWXC4OaYHK5CVxgYNypxe4KCaKuhbFukmVXXMpxYirodSlxNXikDY83RQll62NUjJ+/PioqxAKl0OpTfDs026KUrm3HG2sHXTQQc7LXLp0qfMyXbCpFMXNApUxWXLVikt0Ua1f/6qzLqq4d4vZVIriZl1/MVQKucyiWKXVxT2jKLJ9lEK3mK25VdysReWA64uqBariFUUXVSl0i9lUiuJmgcoB1xdVS0sTDhe/xyi6qFK1NDJtL0Yuh1Kb4FnXXwxZWppwnH/++aGXEUUXVXk5tLWl3h4n9fUWmIqVtaiMydLtt98eehlRdFGlClKZthvjmgUqB0rhnpEJRhRdVF5mkey3G+OaBSoHrr766qirEDtxDv6uZvsn2EADU+gsUDlg94yCF+dA5ZoNNDCFzgZTmEC4zr1nIxuDZQMNTCGzFpUJhOuURtZKNaa7uGYYiSRQicgXRWSNiLSLyKgo6mCCNWHChKirYExJS2QYWb8eVPdkGIlDsIqqRfUC8HngzxGVbwIW12SmxhSLOGcYiSRQqeqLqvq3KMo2xnQX1y6jUhLnxLt2j8qYEhfnLqNSki57SRwS74YWqETkjyLyQorHlByPc4mINItI86ZNm/Kul40WM6azOHcZlZI4z4cTVY2ucJHlwNWq2pzN60eNGqXNzVm91BiTpbIyryXVlYg36dgUj0WLvC8YGzZ4LanZs4tn2oGIrFLVlIPrbB6VMSXO1mqKj7jOh4tqePrnRGQjMAb4HxH5QxT1MMbEu8vIxENUo/5+q6qHqGq1qg5S1U9HUQ9jjKVQMoXPuv6MMbHtMjLxYMPTjTHGFDQLVMYYYwqaBSpjjDEFzQKVMcaYgmaByhhjTEGzQGWMMaagWaAyxhhT0CxQGWOMKWgWqIwxxhQ0C1TGGGMKmgUqY4wxBc0ClTHGuUWLvCXvy8q8f201YZOJJaU1xji1aJG31H1iVeH1673nYIlxTWrWojLGODVr1p4glbBtm7fdmFQsUBljnNqwIbftxligMsY4lW6J+3TbjbFAZYxxavZsb6n7ZL17e9uNScUClTHGqfp6b6n7mhoQ8f694w4bSGHSs1F/xhjn6ustMJnsWYvKGGNMQbNAZYwpCTbJuHhZ158xJvZsknFxsxaVMSb2rQ2bZFzcrEVlTIkrhdaGTTIubtaiMqbElUJrwyYZFzcLVMaUuFJobdgk4+JmgcqYElcKrQ2bZFzcLFAZU+JKpbVRXw8tLdDe7v1rQap4RBKoRORGEXlJRFaLyG9F5IAo6mGMsdaGKXyiqu4LFTkdaFTV3SLyfQBV/cbe3jdq1Chtbm4OvX7GGGPcEpFVqjoq1b5IWlSq+qiq7vaf/gU4JIp6GGOMKXyFcI/qIuCRqCthTDpxnwxrTKELbcKviPwR+GiKXbNU9Xf+a2YBu4G0H30RuQS4BODQOA1DMkWhFCbDGlPoIrlHBSAi04DLgFNUddveXg92j8q4V1vrBaeuamq8kWPGmGBkukcVSQolETkD+AZwcrZBypgolMJkWGMKXVT3qG4D9gWWisizIvKjiOphTEalMBnWmEIXSYtKVY+IolxjcjV7dud7VBDPybDGFLJCGPVnTMGyybDGRM+W+TBmL+rrLTAZEyVrURljjCloFqiMMcYUNAtUxhhjCpoFKmOMMQXNApUxxpiCFlkKpZ4QkU1AioQ2BW8A8E7UlQiZnWM82DnGQzGeY42qDky1o6gCVbESkeZ0Oaziws4xHuwc4yFu52hdf8YYYwqaBSpjjDEFzQKVG3dEXQEH7Bzjwc4xHmJ1jnaPyhhjTEGzFpUxxpiCZoEqRCJygIjcJyIviciLIjIm6joFTUS+JiJrROQFEVksIr2irlO+ROROEXlbRF5I2vYREVkqIn/3/+0XZR3zleYcb/T/VleLyG9F5IAIq5i3VOeYtO9qEVERGRBF3YKS7hxF5Ksi8jf/s3lDVPULigWqcN0C/F5VjwKGAy9GXJ9AicjBwOXAKFUdCpQD50Zbq0DcBZzRZds3gWWq+glgmf+8mN1F93NcCgxV1WHAy8C/u65UwO6i+zkiIh8HTgPisE7zXXQ5RxGZCEwBhqlqHXBTBPUKlAWqkIjIfsB44GcAqrpLVd+PtFLhqAD2EZEKoDfwRsT1yZuq/hl4r8vmKcDd/v/vBj7rsk5BS3WOqvqoqu72n/4FOMR5xQKU5vcI8N/AtUDR36BPc44zgDmqutN/zdvOKxYwC1ThOQzYBCwQkWdE5Kci0ifqSgVJVV/H+7a2AXgT+EBVH422VqEZpKpvAvj/HhhxfcJ2EfBI1JUImoicDbyuqs9FXZcQHQmcJCJ/FZE/icjxUVcoXxaowlMBHAvMV9WRwFaKv7uoE/8+zRRgMPAxoI+InB9trUy+RGQWsBtYFHVdgiQivYFZwHeirkvIKoB+wAnANcC9IiLRVik/FqjCsxHYqKp/9Z/fhxe44uRU4DVV3aSqrcBvgLER1yksb4nIQQD+v0XfnZKKiEwDJgP1Gr+5K4fjfal6TkRa8Lo2nxaRj0Zaq+BtBH6jnqeAdrzcf0XLAlVIVPV/gX+IyBB/0ynA2girFIYNwAki0tv/xnYKMRswkuRBYJr//2nA7yKsSyhE5AzgG8DZqrot6voETVWfV9UDVbVWVWvxLujH+p/VOHkAmAQgIkcCVRRfgtpOLFCF66vAIhFZDYwA/iva6gTLby3eBzwNPI/391T0M+JFZDHwJDBERDaKyJeBOcBpIvJ3vBFjc6KsY77SnONtwL7AUhF5VkR+FGkl85TmHGMlzTneCRzmD1m/B5hW7K1jy0xhjDGmoFmLyhhjTEGzQGWMMaagWaAyxhhT0CxQGWOMKWgWqIwxxhQ0C1TGhEhELhSR2wI+5mdF5JNJz68XkVODLMOYQmKBypji81mgI1Cp6ndU9Y/RVceYcFmgMiYPInK+iDzlT5D9sYiUi8h0EXlZRP4EjEt67V0i8oWk51uS/n+tiDwvIs+JyBx/28UistLfdr+fAWQscDZwo1/m4cnHFZFT/CTIz/trFVX721tE5Hsi8rS/7yhHPyJj8maBypgeEpGjgXOAcao6AmgDzge+hxegTiOp5ZPhOP+C10oararDgcRCd79R1eP9bS8CX1bVJ/DSOV2jqiNUdV3ScXrhrU90jqoeg5ecdEZSUe+o6rHAfODqnp63Ma5ZoDKm504BjgNWisiz/vOvAcv9RL27gF9lcZxTgQWJ/HqqmlhfaKiIPCYizwP1QN1ejjMEL0nwy/7zu/HWREv4jf/vKqA2i3oZUxAsUBnTcwLc7bdsRqjqEOA/SL8g3278z5yfxLcq6Tip3nMX8BW/dfQ9oFcW9clkp/9vG15ry5iiYIHKmJ5bBnxBRA4EEJGPAM8AE0Skv4hUAl9Men0LXgsMvHW8Kv3/Pwpc5K+XlDgOeAli3/SPU590nA/9fV29BNSKyBH+8wuAP/X89IwpDBaojOkhVV0LfBt41M+QvxQ4CK9V9STwR7zM8gk/AU4WkaeA0XiLaaKqv8e779TsdyEm7h9dB/zVP+5LSce5B7jGHzRxeFJ9dgDTgV/73YXtQFFnQDcGLHu6McaYAmctKmOMMQXNApUxxpiCZoHKGGNMQbNAZYwxpqBZoDLGGFPQLFAZY4wpaBaojDHGFDQLVMYYYwra/wfIp9W/6SVr1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sm.graphics.plot_fit(res, \"education\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure to disk\n",
    "fig.savefig('fitted_values.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental Variables Regression Models\n",
    "\n",
    "\n",
    "## IV via 2SLS\n",
    "\n",
    "Of course estimates to the returns to education in the model above are likely biased since education and wages are likely correlated with other factors we aren't (or can't) control for such as cognitive and non-cognitive abilities that make one more productive in school and on the job.\n",
    "\n",
    "To reduce the bias that results from this ommited variable, let's estimate an instrumental variables (IV) model.  Here, we'll argue that the education of the woman's father is correlated with her education level, but not her wages (conditional on her education and experience).  Thus father's education can help provide exogenous variation in education (conditional on father's education and other covariates).\n",
    "\n",
    "One approach to IV models is to use the two-stage least squares (2SLS) estimator, where a model of the woman's eduation is estimated in a first stage:\n",
    "\n",
    "$$ education_{i} = \\gamma_{0} + \\gamma_{1}father\\_education_{i} + \\gamma_{2}experience_{i} + \\gamma_{3} experience^{2}_{i} + u_i $$\n",
    "\n",
    "And then the predicted values of the the woman's education are used in the second stage to estimate the returns to education:\n",
    "\n",
    "\n",
    "$$ ln(wage_{i}) = \\alpha + \\beta_{1} \\hat{education}_i + \\beta_{2}experience_{i} + \\beta_{3} experience^{2}_{i} + \\varepsilon_i $$\n",
    "\n",
    "In this way, we ensure that the error term is uncorrelated with the covariates in the second stage.\n",
    "\n",
    "To estimate this model via 2SLS, we'll use the [`linearmodels.IV2SLS1`](https://bashtage.github.io/linearmodels/doc/iv/examples/advanced-examples.html#2SLS-as-OLS) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                      0.1430\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1370\n",
      "No. Observations:                 428   F-statistic:                    19.229\n",
      "Date:                Tue, Oct 12 2021   P-value (F-stat)                0.0002\n",
      "Time:                        10:26:17   Distribution:                  chi2(3)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                    \n",
      "===========================================================================================\n",
      "                         Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.0611     0.4560    -0.1340     0.8934     -0.9548      0.8326\n",
      "experience                  0.0437     0.0155     2.8187     0.0048      0.0133      0.0740\n",
      "np.power(experience, 2)    -0.0009     0.0004    -2.0552     0.0399     -0.0017   -4.09e-05\n",
      "education                   0.0702     0.0358     1.9632     0.0496      0.0001      0.1403\n",
      "===========================================================================================\n",
      "\n",
      "Endogenous: education\n",
      "Instruments: feducation\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason.debacker/anaconda3/lib/python3.7/site-packages/linearmodels/iv/data.py:25: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  if is_categorical(s):\n"
     ]
    }
   ],
   "source": [
    "# Call the IV2SLS function.\n",
    "wage_IV = lm.IV2SLS.from_formula(\n",
    "    'np.log(wage) ~ 1 + experience + np.power(experience, 2) + [education ~ feducation]',\n",
    "    df)\n",
    "# Estimate the model\n",
    "iv_results = wage_IV.fit()\n",
    "# Show the results\n",
    "print(iv_results.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for endogeneity\n",
    "\n",
    "A standard test to run for IV models is the Hausman test for edogeneity fo the suspected endogenous variable.  This and other tests are available as attributes of the `IV2LS` results object.  We can peer into `iv_results`, which is an instance of this object to see what is available.  We can get a list of the attributes and methods the object has with the `dir()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cov',\n",
       " '_cov_config',\n",
       " '_cov_estimator',\n",
       " '_cov_type',\n",
       " '_datetime',\n",
       " '_debiased',\n",
       " '_df_model',\n",
       " '_endogeneity_setup',\n",
       " '_f_statistic',\n",
       " '_fitted',\n",
       " '_kappa',\n",
       " '_liml_kappa',\n",
       " '_method',\n",
       " '_original_index',\n",
       " '_out_of_sample',\n",
       " '_params',\n",
       " '_r2',\n",
       " '_repr_html_',\n",
       " '_resid',\n",
       " '_rss',\n",
       " '_s2',\n",
       " '_top_right',\n",
       " '_tss',\n",
       " '_update_extra_text',\n",
       " '_vars',\n",
       " '_wresid',\n",
       " 'anderson_rubin',\n",
       " 'basmann',\n",
       " 'basmann_f',\n",
       " 'conf_int',\n",
       " 'cov',\n",
       " 'cov_config',\n",
       " 'cov_estimator',\n",
       " 'cov_type',\n",
       " 'debiased',\n",
       " 'df_model',\n",
       " 'df_resid',\n",
       " 'durbin',\n",
       " 'f_statistic',\n",
       " 'first_stage',\n",
       " 'fitted_values',\n",
       " 'has_constant',\n",
       " 'idiosyncratic',\n",
       " 'kappa',\n",
       " 'method',\n",
       " 'model',\n",
       " 'model_ss',\n",
       " 'nobs',\n",
       " 'params',\n",
       " 'predict',\n",
       " 'pvalues',\n",
       " 'resid_ss',\n",
       " 'resids',\n",
       " 'rsquared',\n",
       " 'rsquared_adj',\n",
       " 's2',\n",
       " 'sargan',\n",
       " 'std_errors',\n",
       " 'summary',\n",
       " 'total_ss',\n",
       " 'tstats',\n",
       " 'wald_test',\n",
       " 'wooldridge_overid',\n",
       " 'wooldridge_regression',\n",
       " 'wooldridge_score',\n",
       " 'wresids',\n",
       " 'wu_hausman']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into the IV Results object\n",
    "dir(iv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a number of test statistics and other results are attributes.  Let's look at the first-stage regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Stage Estimation Results    \n",
      "======================================\n",
      "                             education\n",
      "--------------------------------------\n",
      "R-squared                       0.1755\n",
      "Partial R-squared               0.1715\n",
      "Shea's R-squared                0.1715\n",
      "Partial F-statistic             87.591\n",
      "P-value (Partial F-stat)        0.0000\n",
      "Partial F-stat Distn           chi2(1)\n",
      "========================== ===========\n",
      "Intercept                       9.8870\n",
      "                              (26.424)\n",
      "experience                      0.0468\n",
      "                              (1.0983)\n",
      "np.power(experience, 2)        -0.0012\n",
      "                             (-0.8532)\n",
      "feducation                      0.2705\n",
      "                              (9.3590)\n",
      "--------------------------------------\n",
      "\n",
      "T-stats reported in parentheses\n",
      "T-stats use same covariance type as original model\n"
     ]
    }
   ],
   "source": [
    "print(iv_results.first_stage.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the Wu-Hausman test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Hausman test of exogeneity\n",
      "H0: All endogenous variables are exogenous\n",
      "Statistic: 1.4373\n",
      "P-value: 0.2312\n",
      "Distributed: F(1,423)\n"
     ]
    }
   ],
   "source": [
    "print(iv_results.wu_hausman())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the Wu-Hausman test finds that we can't reject the null hypothesis that OLS is consistent - at least at standard levels of significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV via GMM\n",
    "\n",
    "We can also estimate this instrumental variables model via GMM.  The GMM estimator has the following $K$ moment conditions (where $K$ are the number of instruments in $z_{i}$):\n",
    "\n",
    "$$ g(\\beta_{0}) = E[z_{i}\\varepsilon_{i}] = E[z_{i}(y_{i}-x_{i}^{'}\\beta_{0}] = 0 $$\n",
    "\n",
    "Where $z_{i}$ is the instrument set (e.g., in the example here, $z_{i}$ = a constant, fathers's education, experience, and experience squared (and thus $K=4$).\n",
    "\n",
    "To use this estimator, we'll call the [`linearmodels.IVGMM`](https://bashtage.github.io/linearmodels/doc/iv/methods.html#linearmodels.iv.model.IVGMM) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-GMM Estimation Summary                           \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                      0.1430\n",
      "Estimator:                     IV-GMM   Adj. R-squared:                 0.1370\n",
      "No. Observations:                 428   F-statistic:                    19.229\n",
      "Date:                Tue, Oct 12 2021   P-value (F-stat)                0.0002\n",
      "Time:                        10:28:50   Distribution:                  chi2(3)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                    \n",
      "===========================================================================================\n",
      "                         Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  -0.0611     0.4560    -0.1340     0.8934     -0.9548      0.8326\n",
      "experience                  0.0437     0.0155     2.8187     0.0048      0.0133      0.0740\n",
      "np.power(experience, 2)    -0.0009     0.0004    -2.0552     0.0399     -0.0017   -4.09e-05\n",
      "education                   0.0702     0.0358     1.9632     0.0496      0.0001      0.1403\n",
      "===========================================================================================\n",
      "\n",
      "Endogenous: education\n",
      "Instruments: feducation\n",
      "GMM Covariance\n",
      "Debiased: False\n",
      "Robust (Heteroskedastic)\n"
     ]
    }
   ],
   "source": [
    "# Call the IVGMM function\n",
    "wage_GMM_IV = lm.IVGMM.from_formula(\n",
    "    'np.log(wage) ~ 1 + experience + np.power(experience, 2) + [education ~ feducation]',\n",
    "    df)\n",
    "# Estimate the model\n",
    "iv_gmm_results = wage_GMM_IV.fit()\n",
    "# Show the results\n",
    "print(iv_gmm_results.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect, GMM returns the same point estimats, but different S.E.'s than 2SLS.\n",
    "\n",
    "Now let's estimate an overidentified model.  When we do this, we can do some overidentification tests (e.g. to see that our excluded instruments are exogenous).  We have one potentially endogenous regressor, education.  If we add one more instrument, we will have an over-identified model.  Let's now use mother's education in addition to father's education in the set of excluded instruments.  And let's estimate this model via 2SLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                      0.1357\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1296\n",
      "No. Observations:                 428   F-statistic:                    18.611\n",
      "Date:                Tue, Oct 12 2021   P-value (F-stat)                0.0003\n",
      "Time:                        10:29:36   Distribution:                  chi2(3)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                    \n",
      "===========================================================================================\n",
      "                         Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   0.0481     0.4278     0.1124     0.9105     -0.7903      0.8865\n",
      "experience                  0.0442     0.0155     2.8546     0.0043      0.0138      0.0745\n",
      "np.power(experience, 2)    -0.0009     0.0004    -2.1001     0.0357     -0.0017  -5.997e-05\n",
      "education                   0.0614     0.0332     1.8503     0.0643     -0.0036      0.1264\n",
      "===========================================================================================\n",
      "\n",
      "Endogenous: education\n",
      "Instruments: feducation, meducation\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n",
      "Sargan's test of overidentification\n",
      "H0: The model is not overidentified.\n",
      "Statistic: 0.3781\n",
      "P-value: 0.5386\n",
      "Distributed: chi2(1)\n"
     ]
    }
   ],
   "source": [
    "# Call the IV2SLS function.\n",
    "wage_IV = lm.IV2SLS.from_formula(\n",
    "    'np.log(wage) ~ 1 + experience + np.power(experience, 2) + [education ~ feducation + meducation]',\n",
    "    df)\n",
    "# Estimate the model\n",
    "iv_results = wage_IV.fit()\n",
    "# Show the results\n",
    "print(iv_results.summary)\n",
    "# Show the results of the Sargan over-idenfitication test\n",
    "print(iv_results.sargan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sargan J-Stat has a p-value of 0.5386 meaning that we can't reject the null that the excluded instruments are exogenous (at least at standard levels of significance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing regression output for external use\n",
    "\n",
    "You will want to save model output you are interested in using in a paper/presentation into a format that can easily be put into nicely formated tables.  These tables may be in Excel or LaTeX or something else.  My preferred method has been to:\n",
    "1. Save output from models into text files that are linked to in an Excel workbook\n",
    "2. Have a worksheet in this workbook that reads the raw output from the models and another worksheet that formats the output for presentation (again, linking to the raw output worksheet so not manual manipulation needs to be done after this is initially set up).\n",
    "3. I then use Excel2Latex to create the TeX code that reproduces this table.\n",
    "4. The TeX code is pasted into my TeX document (usually requiring a few adjustments).\n",
    "\n",
    "This may not be the most efficient method, but Excel gives a nice view of the results without having to compile TeX or scroll through a pdf) and there often needs to be some adjustment of variables names etc. to properly size tables and the intermediate step of using Excel can be helpful here.\n",
    "\n",
    "In any case, I show how to output the model results as both TeX code and a text file (for importing into Excel) below.\n",
    "\n",
    "Note that relative to what we did with `R`, Python has less developed packages for automatically formatting output in the standard way economists present regression results (e.g., columns for each model, standard errors under point estimates).   On the othe hand, Python offers lots of flexiblity and it's relatively straightfoward to build your own custom formatted table.\n",
    "\n",
    "## Tables from model results\n",
    "\n",
    "First, note that the `summary` method of the `Results` object from these models has a method to return an ACSII text string or string with the LaTex code for the table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}          &    np.log(wage)    & \\textbf{  R-squared:         } &      0.1357      \\\\\n",
      "\\textbf{Estimator:}              &      IV-2SLS       & \\textbf{  Adj. R-squared:    } &      0.1296      \\\\\n",
      "\\textbf{No. Observations:}       &        428         & \\textbf{  F-statistic:       } &      18.611      \\\\\n",
      "\\textbf{Date:}                   &  Tue, Oct 12 2021  & \\textbf{  P-value (F-stat)   } &      0.0003      \\\\\n",
      "\\textbf{Time:}                   &      10:29:36      & \\textbf{  Distribution:      } &     chi2(3)      \\\\\n",
      "\\textbf{Cov. Estimator:}         &       robust       & \\textbf{                     } &                  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                 & \\textbf{Parameter} & \\textbf{Std. Err.} & \\textbf{T-stat} & \\textbf{P-value} & \\textbf{Lower CI} & \\textbf{Upper CI}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}               &       0.0481       &       0.4278       &      0.1124     &      0.9105      &      -0.7903      &       0.8865       \\\\\n",
      "\\textbf{experience}              &       0.0442       &       0.0155       &      2.8546     &      0.0043      &       0.0138      &       0.0745       \\\\\n",
      "\\textbf{np.power(experience, 2)} &      -0.0009       &       0.0004       &     -2.1001     &      0.0357      &      -0.0017      &     -5.997e-05     \\\\\n",
      "\\textbf{education}               &       0.0614       &       0.0332       &      1.8503     &      0.0643      &      -0.0036      &       0.1264       \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{IV-2SLS Estimation Summary}\n",
      "\\end{center}\n",
      "\n",
      "Endogenous: education \\newline\n",
      " Instruments: feducation, meducation \\newline\n",
      " Robust Covariance (Heteroskedastic) \\newline\n",
      " Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(iv_results.summary.as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, for regression models done in the `statsmodels` package, there is a `summary_col` function that allows one to print multiple modles together in a table that is somewhat similar to what is output from the Stata `outreg` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{}\n",
      "\\label{}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lll}\n",
      "\\hline\n",
      "                        & Model 1  & Model 2   \\\\\n",
      "\\hline\n",
      "Intercept               & -0.5220  & -0.5220   \\\\\n",
      "                        & (0.2017) & (0.2017)  \\\\\n",
      "education               & 0.1075   & 0.1075    \\\\\n",
      "                        & (0.0132) & (0.0132)  \\\\\n",
      "experience              & 0.0416   & 0.0416    \\\\\n",
      "                        & (0.0153) & (0.0153)  \\\\\n",
      "np.power(experience, 2) & -0.0008  & -0.0008   \\\\\n",
      "                        & (0.0004) & (0.0004)  \\\\\n",
      "R-squared               & 0.1568   & 0.1568    \\\\\n",
      "R-squared Adj.          & 0.1509   & 0.1509    \\\\\n",
      "R2                      & 0.1568   & 0.1568    \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# make TeX table of wage_IV2 model\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "# summar_col only works with the statsmodels results - not linearmodels\n",
    "res3 = summary_col([res, res],model_names=['Model 1', 'Model 2'], stars=False, float_format='%0.4f',\n",
    "              info_dict={'R2':lambda x: \"{:.4f}\".format(x.rsquared)})\n",
    "print(res3.as_latex())  # can to as_text or as_html also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "tex_str = res3.as_latex()\n",
    "with open('IVresults.tex', 'w+') as fh:\n",
    "    fh.write(tex_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `Stargazer` package for python that is similar with the `R` library with the same name, although the Python package is less developed.\n",
    "\n",
    "Finally, it's straightforward to pull parameters, standard errors, etc out of the results objects and to place these in a dictionary, which can then put used to create a Latex (or text or html, etc) table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['hours', 'age', 'wage', 'education']].describe().to_latex('summ_stats.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "Christian Kleiber and Achim Zeileis (2008), *Applied Econometrics with R*, Springer-Verlag, New York.\n",
    "ISBN 978-0-387-77316-2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
